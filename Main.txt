
import numpy as np
import torch
from operator import truediv
import torch.utils.data as Data
from sklearn import metrics, preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score
from plotly.offline import init_notebook_mode
import matplotlib.pyplot as plt
import scipy.io as sio
import os
!pip install spectral
import spectral
import cv2
from IPython import display
import math
import torch.nn as nn
import torch.nn.functional as F
from torch.nn import init
from torchsummary import summary
!pip install einops
from einops import rearrange, repeat
init_notebook_mode(connected=True)
%matplotlib inline

!pip install torch-optimizer
import torch_optimizer as optim2
from torch import optim
import time
import collections
import imgaug.augmenters as iaa
import threading
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
import random



# Define function to calculate RÂ² score
def calculate_r2(targets, predictions):
    return r2_score(targets, predictions)

# Define function to calculate RMSE
def calculate_rmse(targets, predictions):
    return np.sqrt(mean_squared_error(targets, predictions))

# Define function to calculate RPD
def calculate_rpd(targets, predictions):
    return np.std(targets) / calculate_rmse(targets, predictions)

#Data Loading

import os
import h5py
import pandas as pd
import re

# Paths to the folders containing the HDF5 and CSV files
hdf5_folder_path = 'Documents/Blueberry_Dataset/'  # Update this path
csv_file_path = 'Documents/Blueberry_Dataset/Sheet_SSC/csv_blueberry_single_row.csv'  # Update this path

# List to store data from HDF5 files and corresponding CSV data
hdf5_data = []
csv_data = []

# Function to sort filenames based on the numerical values in them
def sort_filenames(filenames):
    def extract_numbers(filename):
        numbers = re.findall(r'\d+', filename)
        return list(map(int, numbers))

    return sorted(filenames, key=extract_numbers)

# Function to read data from HDF5 files
def read_hdf5_files(folder_path):
    filenames = [f for f in os.listdir(folder_path) if f.endswith('.h5')]
    sorted_filenames = sort_filenames(filenames)

    for file_name in sorted_filenames:
        file_path = os.path.join(folder_path, file_name)
        with h5py.File(file_path, 'r') as f:
            # Iterate through the keys in the HDF5 file to find the correct dataset name
            for key in f.keys():
                data = f[key][()]  # Try reading the dataset using the identified key
                hdf5_data.append((file_name, data))

# Function to read data from CSV file
def read_csv_file(file_path):
    csv_df = pd.read_csv(file_path)
    csv_values = csv_df.iloc[:, 1]  # Extract values from the second column
    csv_data.extend(csv_values.tolist())

# Call functions to read data
read_hdf5_files(hdf5_folder_path)
read_csv_file(csv_file_path)

# Verify the lengths of both datasets
print("Number of HDF5 files read:", len(hdf5_data))
print("Number of values read from CSV file:", len(csv_data))

# Labeling the HDF5 data with CSV values
labeled_data = []
for i, (file_name, data) in enumerate(hdf5_data):
    if i < len(csv_data):  # Ensure there are enough labels for the HDF5 data
        labeled_data.append((file_name, data, csv_data[i]))

# Print the filenames, shapes, and their corresponding labels
for item in labeled_data:
    print("Filename:", item[0])
    print("Shape:", item[1].shape)
    print("Label:", item[2])

# Optional: Save labeled data to a new file or process as needed


